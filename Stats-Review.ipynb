{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='back'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests \n",
    "\n",
    "### Intro\n",
    "\n",
    "### Table of Contents\n",
    "* <a href='#samplez'>Large Sample z-test for a population proportion</a>\n",
    "    * <a href='#samplez_hype'>Hypotheis Test</a>\n",
    "    * <a href='#samplez_prop'>prop.test function in R</a>\n",
    "\n",
    "\n",
    "* <a href='#samplez_diff'>Large Sample z-test for Difference in Proportion</a>\n",
    "    * <a href='#hype_samplez_diff'>Hypotheis Test</a>\n",
    "    * <a href='#prop_samplez_diff'>prop.test function</a>\n",
    "    \n",
    "    \n",
    "* <a href='#samp_mean'>One sample t-test for population mean</a>\n",
    "    * <a href='#samp_mean_hype'>Hypothesis test</a>\n",
    "    \n",
    "    \n",
    "* <a href='#two_samp'>Two-sample tests</a>\n",
    "    * <a href='#two_samp_ue'>Two sample independent t-test for unequal variance</a>\n",
    "        * <a href='#two_samp_ue_hype'>Hypothesis Test</a>\n",
    "        \n",
    "    * <a href='#paired'>Paired t-test</a>\n",
    "    \n",
    "\n",
    "* <a href='#boot'>Bootstrap confidence intervals</a>\n",
    "\n",
    "\n",
    "* <a href='#rand'>Randomization tests</a>\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.4.3\"-- Attaching packages --------------------------------------- tidyverse 1.2.1 --\n",
      "v ggplot2 2.2.1     v purrr   0.2.4\n",
      "v tibble  1.4.1     v dplyr   0.7.4\n",
      "v tidyr   0.7.2     v stringr 1.2.0\n",
      "v readr   1.1.1     v forcats 0.2.0\n",
      "Warning message:\n",
      "\"package 'tibble' was built under R version 3.4.3\"Warning message:\n",
      "\"package 'tidyr' was built under R version 3.4.2\"Warning message:\n",
      "\"package 'readr' was built under R version 3.4.2\"Warning message:\n",
      "\"package 'purrr' was built under R version 3.4.3\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.4.3\"Warning message:\n",
      "\"package 'forcats' was built under R version 3.4.2\"-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n",
      "\n",
      "Attaching package: 'car'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    recode\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    some\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Packages to load\n",
    "library(tidyverse)\n",
    "library(Lock5Data)\n",
    "library(car)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samplez'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Sample z-test for a population proportion\n",
    "\n",
    "The data set we are looking at is the ChickWeight data set from the datasets package. The columns are: \n",
    "\n",
    "weight - a numeric vector giving the body weight of the chick (gm)  \n",
    "\n",
    "Time - a numeric vector giving the number of days since birth when the measurement was made.\n",
    "\n",
    "Chick - an ordered factor with levels 18 < ... < 48 giving a unique identifier for the chick. The ordering of the levels groups chicks on the same diet together and orders them according to their final weight (lightest to heaviest) within diet.\n",
    "\n",
    "Diet - a factor with levels 1, ..., 4 indicating which experimental diet the chick received.\n",
    "\n",
    "The problem that we are going to be tackling is that in a sample of 220 chicks, after going through diet 1 it was found that a certain number of chicks had a weight greater than 130. The people that provided the diet for the farmer claims that more than 30% of the chicks will weight greater than 130 gm. Find the amount of chicks with a weight greater than 130 and using a significance level equal to .05, test whether this claim is accurate or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>weight</th><th scope=col>Time</th><th scope=col>Chick</th><th scope=col>Diet</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>42</td><td> 0</td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><td>51</td><td> 2</td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><td>59</td><td> 4</td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><td>64</td><td> 6</td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><td>76</td><td> 8</td><td>1 </td><td>1 </td></tr>\n",
       "\t<tr><td>93</td><td>10</td><td>1 </td><td>1 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " weight & Time & Chick & Diet\\\\\n",
       "\\hline\n",
       "\t 42 &  0 & 1  & 1 \\\\\n",
       "\t 51 &  2 & 1  & 1 \\\\\n",
       "\t 59 &  4 & 1  & 1 \\\\\n",
       "\t 64 &  6 & 1  & 1 \\\\\n",
       "\t 76 &  8 & 1  & 1 \\\\\n",
       "\t 93 & 10 & 1  & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "weight | Time | Chick | Diet | \n",
       "|---|---|---|---|---|---|\n",
       "| 42 |  0 | 1  | 1  | \n",
       "| 51 |  2 | 1  | 1  | \n",
       "| 59 |  4 | 1  | 1  | \n",
       "| 64 |  6 | 1  | 1  | \n",
       "| 76 |  8 | 1  | 1  | \n",
       "| 93 | 10 | 1  | 1  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  weight Time Chick Diet\n",
       "1 42      0   1     1   \n",
       "2 51      2   1     1   \n",
       "3 59      4   1     1   \n",
       "4 64      6   1     1   \n",
       "5 76      8   1     1   \n",
       "6 93     10   1     1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'nfnGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':\t578 obs. of  4 variables:\n",
      " $ weight: num  42 51 59 64 76 93 106 125 149 171 ...\n",
      " $ Time  : num  0 2 4 6 8 10 12 14 16 18 ...\n",
      " $ Chick : Ord.factor w/ 50 levels \"18\"<\"16\"<\"15\"<..: 15 15 15 15 15 15 15 15 15 15 ...\n",
      " $ Diet  : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " - attr(*, \"formula\")=Class 'formula'  language weight ~ Time | Chick\n",
      "  .. ..- attr(*, \".Environment\")=<environment: R_EmptyEnv> \n",
      " - attr(*, \"outer\")=Class 'formula'  language ~Diet\n",
      "  .. ..- attr(*, \".Environment\")=<environment: R_EmptyEnv> \n",
      " - attr(*, \"labels\")=List of 2\n",
      "  ..$ x: chr \"Time\"\n",
      "  ..$ y: chr \"Body weight\"\n",
      " - attr(*, \"units\")=List of 2\n",
      "  ..$ x: chr \"(days)\"\n",
      "  ..$ y: chr \"(gm)\"\n"
     ]
    }
   ],
   "source": [
    "#Load in the data and look over a little bit of the data\n",
    "data(ChickWeight)\n",
    "head(ChickWeight)\n",
    "str(ChickWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the data so we only are using chicks that went through diet 1 and chicks greater than 130\n",
    "chick <- filter(ChickWeight, Diet == 1)\n",
    "chick130 <- filter(ChickWeight, Diet == 1 & weight > 130)\n",
    "sample_size <- nrow(chick)\n",
    "greater130_size <- nrow(chick130)\n",
    "alpha <- .05\n",
    "prop  <- .30\n",
    "test_prop <- greater130_size / sample_size\n",
    "test_stat <- (test_prop - prop) / sqrt((prop * (1 - prop)) / sample_size)\n",
    "p_value <- 1 - pnorm(test_stat)\n",
    "conf_int <- c((test_prop - qnorm(1 - (alpha / 2)) * sqrt((test_prop * (1 - test_prop)) / sample_size)), (test_prop + qnorm(1 - (alpha / 2)) * sqrt((test_prop * (1 - test_prop)) / sample_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.268181818181818"
      ],
      "text/latex": [
       "0.268181818181818"
      ],
      "text/markdown": [
       "0.268181818181818"
      ],
      "text/plain": [
       "[1] 0.2681818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-1.02985730108887"
      ],
      "text/latex": [
       "-1.02985730108887"
      ],
      "text/markdown": [
       "-1.02985730108887"
      ],
      "text/plain": [
       "[1] -1.029857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.848461501351687"
      ],
      "text/latex": [
       "0.848461501351687"
      ],
      "text/markdown": [
       "0.848461501351687"
      ],
      "text/plain": [
       "[1] 0.8484615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.209641778346864</li>\n",
       "\t<li>0.326721858016773</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.209641778346864\n",
       "\\item 0.326721858016773\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.209641778346864\n",
       "2. 0.326721858016773\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.2096418 0.3267219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results\n",
    "test_prop\n",
    "test_stat\n",
    "p_value\n",
    "conf_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samplez_hype'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheis Test  for Large Sample z-test for a population proportion\n",
    "\n",
    "#### Assumptions:\n",
    "For this test, observations $x_{1}$, . . . , $x_{n}$ (a sequence of 0’s and 1’s) are a\n",
    "random sample from Bern(p) with p unknown and n is equal to the sample size.\n",
    "\n",
    "The sample size n is large enough to ensure that n$p_{0}$ ≥ 15 and\n",
    "n(1 − $p_{0}$) ≥ 15\n",
    "\n",
    "#### Hypothesis:\n",
    "$$H_{0}: p = .30$$\n",
    "\n",
    "$$H_{a}: p > .30$$\n",
    "\n",
    "\n",
    "#### Test Statistic:\n",
    "\n",
    "$$z=\\frac{\\hat{p}-p_{0}}{\\sqrt{\\frac{p_{0}(1-p_{0})}{n}}}$$\n",
    "\n",
    "$$z=-1.0298$$\n",
    "\n",
    "#### P_value:\n",
    "$$p-value = 0.848461501351687$$\n",
    "\n",
    "#### Conclusion:\n",
    "We fail to reject the null hypothesis at significance level of .05. This however does not mean we accept the alternative hypothesis and more testing need to be done\n",
    "\n",
    "#### Confidence Interval:\n",
    "\n",
    "$$\\hat{p}\\pm z_{(1-\\alpha/2)}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n",
    "\n",
    "For a 95% confidence interval, we are 95% confident that p is in the interval (0.209641778346864, 0.326721858016773), however, the probability that p is in this interval is either 0 or 1. This means that if we were to do this experiment over and over again we are confident that 95% of the time the true population proportion is in this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samplez_prop'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using R's prop.test\n",
    "\n",
    "We can also use R's built in prop.test function if we know the probability ahead of time. The example we will use this time is tossing a coin. Lets say you toss the coin 500 times and it only landed heads 200 times. Test at a .05 significance level if the coin is fair or in other words if the probability of landing heads is not 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t1-sample proportions test with continuity correction\n",
       "\n",
       "data:  200 out of 500, null probability 0.5\n",
       "X-squared = 19.602, df = 1, p-value = 9.537e-06\n",
       "alternative hypothesis: true p is not equal to 0.5\n",
       "95 percent confidence interval:\n",
       " 0.3570044 0.4445558\n",
       "sample estimates:\n",
       "  p \n",
       "0.4 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Prop.test\n",
    "prop.test(x = 200, n = 500, p = 0.5, alternative = \"two.sided\", conf.level = .95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of the results\n",
    "\n",
    "From the prop.test we get a nice layout of the results for the test. We see alternative hypothesis, p-value and the confidence interval as well. From this we can see that the p-value is much less than the .05 significance level and thus we reject the null hypothesis, and we conclude that there is enough statistical evidence to infer that the alternative hypothesis is true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samplez_diff'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Sample z-test for Difference in Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are looking at is the StatGrades dataset found in the Lock5Data package and it contains Stats test scores. The columns are:\n",
    "\n",
    "Exam1: Score (out of 100 points) on the first exam\n",
    "\n",
    "Exam2: Score (out of 100 points) on the second exam\n",
    "\n",
    "Final: Score (out of 100 points) on the final exam\n",
    "\n",
    "The problem that we are going to answer is if there is a greater chance that you will pass the first exam then the second exam where a passing grade is greater than or equal to 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Exam1</th><th scope=col>Exam2</th><th scope=col>Final</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>91</td><td>86</td><td>90</td></tr>\n",
       "\t<tr><td>91</td><td>89</td><td>95</td></tr>\n",
       "\t<tr><td>80</td><td>72</td><td>81</td></tr>\n",
       "\t<tr><td>75</td><td>81</td><td>63</td></tr>\n",
       "\t<tr><td>73</td><td>82</td><td>83</td></tr>\n",
       "\t<tr><td>82</td><td>83</td><td>78</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Exam1 & Exam2 & Final\\\\\n",
       "\\hline\n",
       "\t 91 & 86 & 90\\\\\n",
       "\t 91 & 89 & 95\\\\\n",
       "\t 80 & 72 & 81\\\\\n",
       "\t 75 & 81 & 63\\\\\n",
       "\t 73 & 82 & 83\\\\\n",
       "\t 82 & 83 & 78\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Exam1 | Exam2 | Final | \n",
       "|---|---|---|---|---|---|\n",
       "| 91 | 86 | 90 | \n",
       "| 91 | 89 | 95 | \n",
       "| 80 | 72 | 81 | \n",
       "| 75 | 81 | 63 | \n",
       "| 73 | 82 | 83 | \n",
       "| 82 | 83 | 78 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Exam1 Exam2 Final\n",
       "1 91    86    90   \n",
       "2 91    89    95   \n",
       "3 80    72    81   \n",
       "4 75    81    63   \n",
       "5 73    82    83   \n",
       "6 82    83    78   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t50 obs. of  3 variables:\n",
      " $ Exam1: int  91 91 80 75 73 82 89 47 77 91 ...\n",
      " $ Exam2: int  86 89 72 81 82 83 89 50 74 93 ...\n",
      " $ Final: int  90 95 81 63 83 78 90 74 77 103 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Exam1           Exam2           Final      \n",
       " Min.   :47.00   Min.   :50.00   Min.   : 60.0  \n",
       " 1st Qu.:75.50   1st Qu.:78.00   1st Qu.: 80.0  \n",
       " Median :82.50   Median :86.00   Median : 87.5  \n",
       " Mean   :81.06   Mean   :83.12   Mean   : 85.5  \n",
       " 3rd Qu.:89.00   3rd Qu.:90.00   3rd Qu.: 92.0  \n",
       " Max.   :98.00   Max.   :95.00   Max.   :103.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Look over the data\n",
    "data(StatGrades)\n",
    "head(StatGrades)\n",
    "str(StatGrades)\n",
    "summary(StatGrades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data\n",
    "alpha <- .05\n",
    "exam1_pass <- StatGrades %>% filter(Exam1 >= 75) %>% select(Exam1)\n",
    "exam2_pass <- StatGrades %>% filter(Exam2 >= 75) %>% select(Exam1)\n",
    "size_pass1 <- nrow(exam1_pass)\n",
    "size_pass2 <- nrow(exam2_pass)\n",
    "samp_size <- nrow(StatGrades)\n",
    "samp_prop1 <- size_pass1 / samp_size\n",
    "samp_prop2 <- size_pass2 / samp_size\n",
    "p_hat  <- (size_pass1*samp_prop1 + size_pass2*samp_prop2)/(size_pass1 +size_pass2)\n",
    "test_stat <- (samp_prop1 - samp_prop2) / sqrt(p_hat*(1-p_hat)*((1/size_pass1)+(1/size_pass2)))\n",
    "p_value  <- 1 - pnorm(test_stat)\n",
    "conf_int2 <- c((samp_prop1 - samp_prop2) - qnorm(1 - (alpha/2))*sqrt(((samp_prop1*(1-samp_prop1))/size_pass1) + ((samp_prop2*(1-samp_prop2))/size_pass2)), (samp_prop1 - samp_prop2) + qnorm(1 - (alpha/2))*sqrt(((samp_prop1*(1-samp_prop1))/size_pass1) + ((samp_prop2*(1-samp_prop2))/size_pass2)))\n",
    "conf_int <- c((samp_prop1 - samp_prop2) - qnorm(1 - (alpha/2))*sqrt(p_hat*(1-p_hat)*((1/size_pass1)+(1/size_pass2))), (samp_prop1 - samp_prop2) + qnorm(1 - (alpha/2))*sqrt(p_hat*(1-p_hat)*((1/size_pass1)+(1/size_pass2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.471763853242795"
      ],
      "text/latex": [
       "-0.471763853242795"
      ],
      "text/markdown": [
       "-0.471763853242795"
      ],
      "text/plain": [
       "[1] -0.4717639"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.68145232283435"
      ],
      "text/latex": [
       "0.68145232283435"
      ],
      "text/markdown": [
       "0.68145232283435"
      ],
      "text/plain": [
       "[1] 0.6814523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.206181785320576</li>\n",
       "\t<li>0.126181785320576</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.206181785320576\n",
       "\\item 0.126181785320576\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.206181785320576\n",
       "2. 0.126181785320576\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.2061818  0.1261818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.206308458921961</li>\n",
       "\t<li>0.126308458921961</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.206308458921961\n",
       "\\item 0.126308458921961\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.206308458921961\n",
       "2. 0.126308458921961\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.2063085  0.1263085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Results\n",
    "test_stat\n",
    "p_value\n",
    "conf_int\n",
    "conf_int2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hype_samplez_diff'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheis Test  for Large Sample z-test for difference in proportions\n",
    "\n",
    "#### Assumptions: \n",
    "$x_{11}$, . . . , $x_{1n_{1}}$ and $x_{21}$, . . . , $x_{2n_{2}}$\n",
    "are random samples from two independent Bernoulli populations Bern($p_{1}$) and Bern($p_{2}$)\n",
    "respectively with at least 10 successes and 10 failures in both groups.\n",
    "\n",
    "$$ n_{1}\\hat{p_{1}}\\geq 10,\\quad n_{1}(1−\\hat{p_{1}})\\geq 10 \\quad and \\quad n_{2}\\hat{p_{2}}\\geq 10,\\quad n_{2}(1−\\hat{p_{2}})\\geq 10$$\n",
    "\n",
    "#### Hypothesis\n",
    "$$H_{0}: p_{1} - p_{2} = 0$$\n",
    "\n",
    "$$H_{a}: p_{1} - p_{2} > 0$$\n",
    "\n",
    "#### Test Statistic\n",
    "\n",
    "$$z=\\frac{\\hat{p_{1}}-\\hat{p_{2}}-0}{\\sqrt{\\hat{p}(1 - \\hat{p})(1/n_{1} + 1/n_{2})}}$$\n",
    "\n",
    "where $\\hat{p} = (n_{1}\\hat{p_{1}} + n_{2}\\hat{p_{2}})/(n_{1} + n_{2})$\n",
    "\n",
    "$$ z= -0.471763853242795$$\n",
    "\n",
    "#### P-value\n",
    "\n",
    "$$p-value = 0.68145232283435$$\n",
    "\n",
    "#### Conclusion \n",
    "\n",
    "Because the p-value is found to be greater than the .05 significance level, we fail to reject the null hypothesis and we can not conclude whether or not the their is a higher chance to pass the first exam compared to the second one.\n",
    "\n",
    "#### Confidence Interval\n",
    "\n",
    "$$(\\hat{p_{1}}-\\hat{p_{2}})\\pm z_{(1-\\alpha/2)}SE$$\n",
    "\n",
    "Where SE is the denominator of the test statistics (didn't want to write the Latex of it :p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prop_samplez_diff'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using prop.test\n",
    "\n",
    "Just like in the large sample z test for population proportion we can do most of these calculation using prop.test except this time the parameters will be taking a list of the proportions and also each of the proportions sample size. We will have a nicely laid out example with all the values we need. Lets say we want to see if mean and women are equally likely to go to a a 4 year college after high school. 12000 people are sampled where 5622 are men and 6378 are women and out of those men 3004 went to college while 4234 went to college on the womens side. Test whether this claim is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t2-sample test for equality of proportions with continuity correction\n",
       "\n",
       "data:  c(men_coll, women_coll) out of c(samp_men, samp_women)\n",
       "X-squared = 208.87, df = 1, p-value < 2.2e-16\n",
       "alternative hypothesis: two.sided\n",
       "95 percent confidence interval:\n",
       " -0.1471301 -0.1119000\n",
       "sample estimates:\n",
       "   prop 1    prop 2 \n",
       "0.5343294 0.6638445 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "men_coll <- 3004\n",
    "women_coll <- 4234\n",
    "samp_men <- 5622\n",
    "samp_women <- 6378\n",
    "prop.test(x = c(men_coll, women_coll), n = c(samp_men, samp_women), alternative = 'two.sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "From this we can now make a conclusion that with p-value less than the .05 significance value, we can reject the null hypothesis and conclude that there is statistical evidence towards the two population proportions not being equal. In other words males and females seem to not have the same proportion of going to college."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samp_mean'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disclaimer\n",
    "In the following sections we will be focusing more on the functions and will not be writing out the formulas anymore (I got tired writing so much Latex haha). If you want to know the formulas pleas google them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample t-test for a population mean\n",
    "\n",
    "The data set we will be using is the FloridaLakes dataset in the Lock5Data package and we will test to see if this sample provides evidence that the average alkalinity of all Florida lakes is greater than 40 mg/L. We will be using the t.test function in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ID</th><th scope=col>Lake</th><th scope=col>Alkalinity</th><th scope=col>pH</th><th scope=col>Calcium</th><th scope=col>Chlorophyll</th><th scope=col>AvgMercury</th><th scope=col>NumSamples</th><th scope=col>MinMercury</th><th scope=col>MaxMercury</th><th scope=col>ThreeYrStdMercury</th><th scope=col>AgeData</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1           </td><td>Alligator   </td><td>  5.9       </td><td>6.1         </td><td> 3.0        </td><td>  0.7       </td><td>1.23        </td><td> 5          </td><td>0.85        </td><td>1.43        </td><td>1.53        </td><td>1           </td></tr>\n",
       "\t<tr><td>2           </td><td>Annie       </td><td>  3.5       </td><td>5.1         </td><td> 1.9        </td><td>  3.2       </td><td>1.33        </td><td> 7          </td><td>0.92        </td><td>1.90        </td><td>1.33        </td><td>0           </td></tr>\n",
       "\t<tr><td>3           </td><td>Apopka      </td><td>116.0       </td><td>9.1         </td><td>44.1        </td><td>128.3       </td><td>0.04        </td><td> 6          </td><td>0.04        </td><td>0.06        </td><td>0.04        </td><td>0           </td></tr>\n",
       "\t<tr><td>4           </td><td>Blue Cypress</td><td> 39.4       </td><td>6.9         </td><td>16.4        </td><td>  3.5       </td><td>0.44        </td><td>12          </td><td>0.13        </td><td>0.84        </td><td>0.44        </td><td>0           </td></tr>\n",
       "\t<tr><td>5           </td><td>Brick       </td><td>  2.5       </td><td>4.6         </td><td> 2.9        </td><td>  1.8       </td><td>1.20        </td><td>12          </td><td>0.69        </td><td>1.50        </td><td>1.33        </td><td>1           </td></tr>\n",
       "\t<tr><td>6           </td><td>Bryant      </td><td> 19.6       </td><td>7.3         </td><td> 4.5        </td><td> 44.1       </td><td>0.27        </td><td>14          </td><td>0.04        </td><td>0.48        </td><td>0.25        </td><td>1           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       " ID & Lake & Alkalinity & pH & Calcium & Chlorophyll & AvgMercury & NumSamples & MinMercury & MaxMercury & ThreeYrStdMercury & AgeData\\\\\n",
       "\\hline\n",
       "\t 1            & Alligator    &   5.9        & 6.1          &  3.0         &   0.7        & 1.23         &  5           & 0.85         & 1.43         & 1.53         & 1           \\\\\n",
       "\t 2            & Annie        &   3.5        & 5.1          &  1.9         &   3.2        & 1.33         &  7           & 0.92         & 1.90         & 1.33         & 0           \\\\\n",
       "\t 3            & Apopka       & 116.0        & 9.1          & 44.1         & 128.3        & 0.04         &  6           & 0.04         & 0.06         & 0.04         & 0           \\\\\n",
       "\t 4            & Blue Cypress &  39.4        & 6.9          & 16.4         &   3.5        & 0.44         & 12           & 0.13         & 0.84         & 0.44         & 0           \\\\\n",
       "\t 5            & Brick        &   2.5        & 4.6          &  2.9         &   1.8        & 1.20         & 12           & 0.69         & 1.50         & 1.33         & 1           \\\\\n",
       "\t 6            & Bryant       &  19.6        & 7.3          &  4.5         &  44.1        & 0.27         & 14           & 0.04         & 0.48         & 0.25         & 1           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "ID | Lake | Alkalinity | pH | Calcium | Chlorophyll | AvgMercury | NumSamples | MinMercury | MaxMercury | ThreeYrStdMercury | AgeData | \n",
       "|---|---|---|---|---|---|\n",
       "| 1            | Alligator    |   5.9        | 6.1          |  3.0         |   0.7        | 1.23         |  5           | 0.85         | 1.43         | 1.53         | 1            | \n",
       "| 2            | Annie        |   3.5        | 5.1          |  1.9         |   3.2        | 1.33         |  7           | 0.92         | 1.90         | 1.33         | 0            | \n",
       "| 3            | Apopka       | 116.0        | 9.1          | 44.1         | 128.3        | 0.04         |  6           | 0.04         | 0.06         | 0.04         | 0            | \n",
       "| 4            | Blue Cypress |  39.4        | 6.9          | 16.4         |   3.5        | 0.44         | 12           | 0.13         | 0.84         | 0.44         | 0            | \n",
       "| 5            | Brick        |   2.5        | 4.6          |  2.9         |   1.8        | 1.20         | 12           | 0.69         | 1.50         | 1.33         | 1            | \n",
       "| 6            | Bryant       |  19.6        | 7.3          |  4.5         |  44.1        | 0.27         | 14           | 0.04         | 0.48         | 0.25         | 1            | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  ID Lake         Alkalinity pH  Calcium Chlorophyll AvgMercury NumSamples\n",
       "1 1  Alligator      5.9      6.1  3.0      0.7       1.23        5        \n",
       "2 2  Annie          3.5      5.1  1.9      3.2       1.33        7        \n",
       "3 3  Apopka       116.0      9.1 44.1    128.3       0.04        6        \n",
       "4 4  Blue Cypress  39.4      6.9 16.4      3.5       0.44       12        \n",
       "5 5  Brick          2.5      4.6  2.9      1.8       1.20       12        \n",
       "6 6  Bryant        19.6      7.3  4.5     44.1       0.27       14        \n",
       "  MinMercury MaxMercury ThreeYrStdMercury AgeData\n",
       "1 0.85       1.43       1.53              1      \n",
       "2 0.92       1.90       1.33              0      \n",
       "3 0.04       0.06       0.04              0      \n",
       "4 0.13       0.84       0.44              0      \n",
       "5 0.69       1.50       1.33              1      \n",
       "6 0.04       0.48       0.25              1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  FloridaLakes$Alkalinity\n",
       "t = 2.3878, df = 52, p-value = 0.01031\n",
       "alternative hypothesis: true mean is greater than 25\n",
       "95 percent confidence interval:\n",
       " 28.74199      Inf\n",
       "sample estimates:\n",
       "mean of x \n",
       " 37.53019 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(FloridaLakes)\n",
    "head(FloridaLakes)\n",
    "t.test(FloridaLakes$Alkalinity, alternative = 'greater', mu = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samp_mean_hype'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test\n",
    "\n",
    "#### Assumptions:\n",
    "\n",
    "Observations $x_{1}$, . . . , $x_{n}$ are a random sample from the normal distribution N(µ, σ)\n",
    "\n",
    "#### Hypothesis:\n",
    "\n",
    "$$H_{0}: µ > 30$$\n",
    "$$H_{a}: µ > 30$$\n",
    "\n",
    "#### T-test:\n",
    "\n",
    "$$ t = 2.3878$$\n",
    "\n",
    "*We use this test when σ is not known\n",
    "\n",
    "#### P-value:\n",
    "\n",
    "$$ p-value = 0.01031$$\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "Because the p-value is less than the .05 significance level, we can reject the null hypothesis and conclude that we have enough statistical evidence that the claim is true.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='two_samp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Sample t-test for difference in means\n",
    "\n",
    "We will belooking mainly at two different ways to do this kind of test. The first will focus on when the two samples are independent and they both have unequal variance(Two-sample independent t-test). One example is the exam score of students trained with method 1 to those trained with method 2.\n",
    "\n",
    "The second test we will be looking at is when the two samples are not independent and are connected with some sort of treatment or effect. For example, the before and after of students that got a certain learning program and see how well this program worked. This test is called the paired t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='two_samp_ue'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sample independent t-test for unequal variance\n",
    "\n",
    "#### Rationale\n",
    "Usually we would choose the test for unequal variance when there were unequal sample size between the independent sample and choose equal when there were equal sample sizes. However much research has been done on this topic and it has shown that the t-test for unequal variance for two independent samples(Welch Test) performs better than Student's t-test whenever sample sizes and variances are unequal between groups, and gives the same result when sample sizes and variances are equal. except when the sample sizes are very small(5 subjects or less). \n",
    "\n",
    "Great resource that looks more into this: http://daniellakens.blogspot.com.es/2015/01/always-use-welchs-t-test-instead-of.html\n",
    "\n",
    "#### Example\n",
    "\n",
    "We will be looking at the ColaCalcium dataset in the Lock5Data and the questions we will try to answer is if the calcium level in diet cola is greater than the calcium level in water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Drink</th><th scope=col>Calcium</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Diet cola</td><td>50       </td></tr>\n",
       "\t<tr><td>Diet cola</td><td>62       </td></tr>\n",
       "\t<tr><td>Diet cola</td><td>48       </td></tr>\n",
       "\t<tr><td>Diet cola</td><td>55       </td></tr>\n",
       "\t<tr><td>Diet cola</td><td>58       </td></tr>\n",
       "\t<tr><td>Diet cola</td><td>61       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Drink & Calcium\\\\\n",
       "\\hline\n",
       "\t Diet cola & 50       \\\\\n",
       "\t Diet cola & 62       \\\\\n",
       "\t Diet cola & 48       \\\\\n",
       "\t Diet cola & 55       \\\\\n",
       "\t Diet cola & 58       \\\\\n",
       "\t Diet cola & 61       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Drink | Calcium | \n",
       "|---|---|---|---|---|---|\n",
       "| Diet cola | 50        | \n",
       "| Diet cola | 62        | \n",
       "| Diet cola | 48        | \n",
       "| Diet cola | 55        | \n",
       "| Diet cola | 58        | \n",
       "| Diet cola | 61        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Drink     Calcium\n",
       "1 Diet cola 50     \n",
       "2 Diet cola 62     \n",
       "3 Diet cola 48     \n",
       "4 Diet cola 55     \n",
       "5 Diet cola 58     \n",
       "6 Diet cola 61     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t16 obs. of  2 variables:\n",
      " $ Drink  : Factor w/ 2 levels \"Diet cola\",\"Water\": 1 1 1 1 1 1 1 1 2 2 ...\n",
      " $ Calcium: int  50 62 48 55 58 61 58 56 48 46 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  Calcium by Drink\n",
       "t = 3.1732, df = 12.89, p-value = 0.003703\n",
       "alternative hypothesis: true difference in means is greater than 0\n",
       "95 percent confidence interval:\n",
       " 3.035583      Inf\n",
       "sample estimates:\n",
       "mean in group Diet cola     mean in group Water \n",
       "                 56.000                  49.125 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Review data and conduct test\n",
    "data(ColaCalcium)\n",
    "head(ColaCalcium)\n",
    "str(ColaCalcium)\n",
    "t.test(Calcium~Drink, ColaCalcium, alternative = 'greater')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='two_samp_ue_hype'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis test\n",
    "\n",
    "#### Assumptions:\n",
    "Observations $x_{11}$, . . . , $x_{1n_{1}}$ and $x_{21}$, . . . , $x_{2n_{2}}$\n",
    "are random samples from two distinct normal populations N($µ_{1}$, $σ_{1}$) and N($µ_{2}$, $σ_{2}$).\n",
    "\n",
    "#### Hypothesis:\n",
    "\n",
    "$$H_{0}: \\mu_{1} - \\mu_{2} = 0$$\n",
    "$$H_{a}: \\mu_{1} - \\mu_{2} > 0$$\n",
    "\n",
    "#### T-statistic:\n",
    "\n",
    "$$t = 3.1732$$\n",
    "\n",
    "#### P-value\n",
    "\n",
    "$$p-value = 0.003703$$\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paired\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired t-test for difference in means\n",
    "\n",
    "We will be using the Wetsuits dataset from the Lock5Data package. From this we will see whether their is a difference between the max velocity of swimmers swimming with a wetsuit and the smae swimmers swimming without one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Wetsuit</th><th scope=col>NoWetsuit</th><th scope=col>Gender</th><th scope=col>Type</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1.57      </td><td>1.49      </td><td>F         </td><td>swimmer   </td></tr>\n",
       "\t<tr><td>1.47      </td><td>1.37      </td><td>F         </td><td>triathlete</td></tr>\n",
       "\t<tr><td>1.42      </td><td>1.35      </td><td>F         </td><td>swimmer   </td></tr>\n",
       "\t<tr><td>1.35      </td><td>1.27      </td><td>F         </td><td>triathlete</td></tr>\n",
       "\t<tr><td>1.22      </td><td>1.12      </td><td>M         </td><td>triathlete</td></tr>\n",
       "\t<tr><td>1.75      </td><td>1.64      </td><td>M         </td><td>swimmer   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Wetsuit & NoWetsuit & Gender & Type\\\\\n",
       "\\hline\n",
       "\t 1.57       & 1.49       & F          & swimmer   \\\\\n",
       "\t 1.47       & 1.37       & F          & triathlete\\\\\n",
       "\t 1.42       & 1.35       & F          & swimmer   \\\\\n",
       "\t 1.35       & 1.27       & F          & triathlete\\\\\n",
       "\t 1.22       & 1.12       & M          & triathlete\\\\\n",
       "\t 1.75       & 1.64       & M          & swimmer   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Wetsuit | NoWetsuit | Gender | Type | \n",
       "|---|---|---|---|---|---|\n",
       "| 1.57       | 1.49       | F          | swimmer    | \n",
       "| 1.47       | 1.37       | F          | triathlete | \n",
       "| 1.42       | 1.35       | F          | swimmer    | \n",
       "| 1.35       | 1.27       | F          | triathlete | \n",
       "| 1.22       | 1.12       | M          | triathlete | \n",
       "| 1.75       | 1.64       | M          | swimmer    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Wetsuit NoWetsuit Gender Type      \n",
       "1 1.57    1.49      F      swimmer   \n",
       "2 1.47    1.37      F      triathlete\n",
       "3 1.42    1.35      F      swimmer   \n",
       "4 1.35    1.27      F      triathlete\n",
       "5 1.22    1.12      M      triathlete\n",
       "6 1.75    1.64      M      swimmer   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t12 obs. of  4 variables:\n",
      " $ Wetsuit  : num  1.57 1.47 1.42 1.35 1.22 1.75 1.64 1.57 1.56 1.53 ...\n",
      " $ NoWetsuit: num  1.49 1.37 1.35 1.27 1.12 1.64 1.59 1.52 1.5 1.45 ...\n",
      " $ Gender   : Factor w/ 2 levels \"F\",\"M\": 1 1 1 1 2 2 2 2 2 2 ...\n",
      " $ Type     : Factor w/ 2 levels \"swimmer\",\"triathlete\": 1 2 1 2 2 1 1 2 2 2 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tPaired t-test\n",
       "\n",
       "data:  Wetsuits$Wetsuit and Wetsuits$NoWetsuit\n",
       "t = 12.318, df = 11, p-value = 8.885e-08\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.06365244 0.09134756\n",
       "sample estimates:\n",
       "mean of the differences \n",
       "                 0.0775 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(Wetsuits)\n",
    "head(Wetsuits)\n",
    "str(Wetsuits)\n",
    "t.test(Wetsuits$Wetsuit, Wetsuits$NoWetsuit, paired = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The p-value found was less than the .05 significane level, thus we can reject the null hypotheis that the difference in means is equal to 0 and conclude that the true differnece between the two methods is not equal to 0. We see that their is a difference when swimming withthe wetsuit and without the wetsuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boot'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomization Test(Monte Carlo Permutation test)\n",
    "\n",
    "Randomization tests rely on fewer assumptions than do common parametric tests (such as the t-test) and so can be used when\n",
    "requirements for parametric tests are not satisfied, and they can sometimes be more powerful than common\n",
    "rank-based nonparametric tests and so also can be used when typical nonparametric tests are not desired.\n",
    "\n",
    "We will be seing how powerful the test is in comparison to a one sample t-test and also look at how to implment a randomization test and the bootstrap confidence interval in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap confidence interval\n",
    "\n",
    "We use the bootstrap confidence interval on some values of samples such as st. dev., correlation, and other metrics in order to get the sampling distribution from one samaple without the need to have assumptions met that usually are very loosely met. We will be looking at how to code this confidence interval in R.\n",
    "\n",
    "(1-α)% confidence interval using t distribtution(we can use other distributions too:\n",
    "\n",
    "$$Stat_{PE}\\pm t_{1-\\alpha/2,n-1}*SE_{boot}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t110 obs. of  4 variables:\n",
      " $ population: int  675 713 NA 534 1261 1330 331 1981 315 305 ...\n",
      " $ nonwhite  : num  7.3 2.6 3.3 0.8 1.4 22.8 7 21.6 20.7 0.6 ...\n",
      " $ density   : int  746 322 NA 491 1612 770 41 877 240 147 ...\n",
      " $ crime     : int  2602 1388 5018 1182 3341 2805 3306 4256 2117 1063 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   population         nonwhite        density            crime     \n",
       " Min.   :  270.0   Min.   : 0.30   Min.   :   37.0   Min.   : 458  \n",
       " 1st Qu.:  398.8   1st Qu.: 3.40   1st Qu.:  266.5   1st Qu.:2067  \n",
       " Median :  664.0   Median : 7.20   Median :  412.0   Median :2698  \n",
       " Mean   : 1136.0   Mean   :10.80   Mean   :  765.7   Mean   :2714  \n",
       " 3rd Qu.: 1167.8   3rd Qu.:14.88   3rd Qu.:  773.2   3rd Qu.:3305  \n",
       " Max.   :11551.0   Max.   :64.30   Max.   :13087.0   Max.   :5441  \n",
       " NA's   :10                        NA's   :10                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#By Hand\n",
    "#### First get Freedman dataset from cars library\n",
    "data(Freedman)\n",
    "summary(Freedman)\n",
    "Freedman <- na.omit(Freedman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   population         nonwhite        density            crime     \n",
       " Min.   :  270.0   Min.   : 0.30   Min.   :   37.0   Min.   : 458  \n",
       " 1st Qu.:  398.8   1st Qu.: 3.40   1st Qu.:  266.5   1st Qu.:2100  \n",
       " Median :  664.0   Median : 7.30   Median :  412.0   Median :2762  \n",
       " Mean   : 1136.0   Mean   :10.66   Mean   :  765.7   Mean   :2733  \n",
       " 3rd Qu.: 1167.8   3rd Qu.:14.82   3rd Qu.:  773.2   3rd Qu.:3318  \n",
       " Max.   :11551.0   Max.   :64.30   Max.   :13087.0   Max.   :5441  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.11222828354642"
      ],
      "text/latex": [
       "0.11222828354642"
      ],
      "text/markdown": [
       "0.11222828354642"
      ],
      "text/plain": [
       "[1] 0.1122283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "100"
      ],
      "text/latex": [
       "100"
      ],
      "text/markdown": [
       "100"
      ],
      "text/plain": [
       "[1] 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We have omitted all the NA values now lets find the correlation between density  and the crime for a city\n",
    "summary(Freedman)\n",
    "cor(Freedman$density, Freedman$crime)\n",
    "nrow(Freedman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"Histogram of boot_dist\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Not that much of a correlation now lets make a bootstrap confidence interval for the correlation\n",
    "cor_boot <- function(num_boot, samp_size, x, y){\n",
    "    \n",
    "    boot_dist <- rep(NA, num_boot)\n",
    "    #Dont usually want to use for loops in R, will later fix to apply function\n",
    "    for (i in 1:num_boot){\n",
    "        #Sample with replacement the sample size \n",
    "        boot_sample<-sample(samp_size, replace = TRUE)\n",
    "        #For each of the samples we find the correlations and put it into the list\n",
    "        boot_dist[i]<-cor(x[boot_sample], y[boot_sample])\n",
    "    }\n",
    "    \n",
    "    hist(boot_dist)\n",
    "    return(boot_dist)\n",
    "}\n",
    "\n",
    "boot_dist <- cor_boot(5000, nrow(Freedman), Freedman$density, Freedman$crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.151396451337555</li>\n",
       "\t<li>0.375853018430395</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.151396451337555\n",
       "\\item 0.375853018430395\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.151396451337555\n",
       "2. 0.375853018430395\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.1513965  0.3758530"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sample correlation +- t * se of the bootstrap dist\n",
    "cor(Freedman$density,Freedman$crime)+c(-1,1)*qt(0.975,nrow(Freedman))*sd(boot_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of results\n",
    "We are 95% confident that the true correlation between density and crime is between the values -0.1514 and 0.3758."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rand'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomization test\n",
    "\n",
    "Why use it - Dont have to assume a distribution and does not need to be randomly sampled however it nevertheless remains important for randomization tests that the data come from an experiment in which experimental units have been randomly assigned to treatments. We will first go over some topics such as Type 1 and Type 2 error and then do a power analysis to see how it does compared to its conunterpart test.\n",
    "\n",
    "#### Formal Definitions\n",
    "\n",
    "Type 1 error - the error of rejecting a null\n",
    "hypothesis when it is actually true.\n",
    "\n",
    "Type 2 error - the error of not rejecting a null\n",
    "hypothesis when the alternative hypothesis is true.\n",
    "\n",
    "Statistical Power - The power of a study is the likelihood that it will distinguish an effect of a certain size from pure luck. Also 1 - Type 2 error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to do a randomization test for one sample\n",
    "\n",
    "The problem we are looking at is levels of toxins in different food products. We only get a couple of samples (6) and we need to find out if the products have a mean level greater than 80. Because the one sample t-test for population mean has its assumption of sample size violated so we use the randomization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.1166"
      ],
      "text/latex": [
       "0.1166"
      ],
      "text/markdown": [
       "0.1166"
      ],
      "text/plain": [
       "[1] 0.1166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the sample mean of the samples\n",
    "toxin <- c(68, 75, 81, 93, 95, 134)\n",
    "set.seed(123)\n",
    "doRandTestOne <- function(samples, times, null){\n",
    "    \n",
    "    rand_dist <- rep(NA,times)\n",
    "    #Adjust value in the original sample by 91-80 = 11 to center\n",
    "    adjusted <- samples - (mean(samples) - null)\n",
    "    for(i in 1:times){\n",
    "        \n",
    "        rand_sample <- sample(length(samples),replace = TRUE)\n",
    "        rand_dist[i] <- mean(adjusted[rand_sample])\n",
    "    }\n",
    "    #Determine the proportion of samples greater than the original mean, 91\n",
    "    p_value <- mean(rand_dist >= mean(samples))\n",
    "    \n",
    "    return(p_value)\n",
    "}\n",
    "\n",
    "doRandTestOne(toxin, 10000, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Using the function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#back'>Back to the top</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
